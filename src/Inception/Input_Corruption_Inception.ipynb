{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchsummary import summary\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.CenterCrop(28),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./CIFAR', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./CIFAR', train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=32, shuffle=True, num_workers=2,pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=32, shuffle=False, num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(training_loss_arr, validation_loss_arr, training_acc_arr, validation_acc_arr, \\\n",
    "                title):\n",
    "    num_epochs = len(training_loss_arr)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = plt.gca()\n",
    "    ax.plot(range(num_epochs), training_loss_arr, '-bo', label=\"Training Loss\")\n",
    "    ax.plot(range(num_epochs), validation_loss_arr, '-ro', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(title)\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = plt.gca()\n",
    "    ax.plot(range(num_epochs), training_acc_arr, '-bo', label=\"Training Acc\")\n",
    "    ax.plot(range(num_epochs), validation_acc_arr, '-ro', label=\"Validation Acc\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(title)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvModule, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    " \n",
    "\"\"\"\n",
    "La clase InceptionModule en PyTorch define un módulo que simula el funcionamiento de un módulo de tipo Inception, que es una arquitectura popular en redes neuronales\n",
    "convolucionales utilizada en modelos como GoogLeNet. Esta arquitectura se basa en la idea de aplicar convoluciones de diferentes tamaños en paralelo y luego\n",
    "concatenar los resultados.\n",
    "\"\"\"\n",
    "class InceptionModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, f_1x1, f_3x3):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvModule(in_channels, f_1x1, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvModule(in_channels, f_3x3, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        return torch.cat([branch1, branch2], 1)\n",
    "\n",
    "\n",
    "class DownsampleModule(nn.Module):\n",
    "    def __init__(self, in_channels, f_3x3):\n",
    "        super(DownsampleModule, self).__init__()\n",
    "    \n",
    "        self.branch1 = nn.Sequential(ConvModule(in_channels, f_3x3, kernel_size=3, stride=2, padding=0))\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        return torch.cat([branch1, branch2], 1)\n",
    "   \n",
    "class InceptionNet(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvModule(in_channels =3,out_channels=96, kernel_size=3, stride=1, padding=0)\n",
    "        self.inception1 = InceptionModule(in_channels=96,f_1x1=32,f_3x3=32)\n",
    "        self.inception2 = InceptionModule(in_channels=64,f_1x1=32,f_3x3=48)\n",
    "        self.down1 = DownsampleModule(in_channels=80,f_3x3=80)\n",
    "        self.inception3 = InceptionModule(in_channels=160,f_1x1=112,f_3x3=48)\n",
    "        self.inception4 = InceptionModule(in_channels=160,f_1x1=96,f_3x3=64)\n",
    "        self.inception5 = InceptionModule(in_channels=160,f_1x1=80,f_3x3=80)\n",
    "        self.inception6 = InceptionModule(in_channels=160,f_1x1=48,f_3x3=96)   \n",
    "        self.down2 = DownsampleModule(in_channels=144,f_3x3=96)\n",
    "        self.inception7 = InceptionModule(in_channels=240,f_1x1=176,f_3x3=160)\n",
    "        self.inception8 = InceptionModule(in_channels=336,f_1x1=176,f_3x3=160)\n",
    "        self.meanpool = nn.AdaptiveAvgPool2d((7,7))\n",
    "        self.fc = nn.Linear(16464, num_classes)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.inception7(x)\n",
    "        x = self.inception8(x)\n",
    "        x = self.meanpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device():\n",
    "  if torch.cuda.is_available():\n",
    "      return torch.device('cuda')\n",
    "  else:\n",
    "      return torch.device('cpu')\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_single_epoch(train_loader, model, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()*len(inputs)\n",
    "        if batch_num%200==0:\n",
    "            print(\"Batch {} Loss: {}\".format(batch_num, loss.item()))\n",
    "        preds = outputs.argmax(1)\n",
    "        num_correct += (preds==labels).sum().item()\n",
    "    epoch_loss = running_loss/len(train_loader.sampler)\n",
    "    epoch_acc = num_correct/len(train_loader.sampler)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation_single_epoch(valid_loader, model, device, criterion):\n",
    "    running_loss = 0.0\n",
    "    num_correct = 0\n",
    "    for batch_num, data in enumerate(valid_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()*len(inputs)\n",
    "        preds = outputs.argmax(1)\n",
    "        num_correct += (preds==labels).sum().item()\n",
    "    epoch_loss = running_loss/len(valid_loader.sampler)\n",
    "    epoch_acc = num_correct/len(valid_loader.sampler)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_image(batch, w, h):\n",
    "    # CIFAR 10 mean and std in RGB format. Source: https://github.com/facebookarchive/fb.resnet.torch/issues/180\n",
    "    mean = [125.3, 123.0, 113.9]\n",
    "    std = [63.0, 62.1, 66.7]\n",
    "    out = list()\n",
    "    for i in range(batch):\n",
    "        r_channel = torch.normal(mean[0], std[0], size=(w, h)).unsqueeze(0)\n",
    "        g_channel = torch.normal(mean[1], std[1], size=(w, h)).unsqueeze(0)\n",
    "        b_channel = torch.normal(mean[2], std[2], size=(w, h)).unsqueeze(0)\n",
    "        out.append(torch.cat((r_channel, g_channel, b_channel), dim=0).unsqueeze(0))\n",
    "    return torch.cat(out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model,trainloader,testloader):\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    total += labels.size(0)\n",
    "    correct += (preds == labels).sum().item()\n",
    "  acc_v = (correct / total)\n",
    "  correct = 0\n",
    "  total = 0            \n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    total += labels.size(0)\n",
    "    correct += (preds == labels).sum().item()\n",
    "  acc_t = (correct / total)\n",
    "  return acc_t,acc_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(epoch, model, trainloader, testloader, optimizer,scheduler,name='model', random_shuffle=False, shuffled_pixels=False, random_pixels=False, gaussian_noise=False):\n",
    "  train_losses, valid_losses = [], []\n",
    "  train_accs, valid_accs = [], []\n",
    "  history_t = []\n",
    "  history_v = []\n",
    "  history_loss = []\n",
    "  step_count = 0\n",
    "  highest_acc = 1e-10\n",
    "  \n",
    "  criterion = nn.CrossEntropyLoss().to(device)\n",
    "  # Establish the random seed for the model\n",
    "  if random_pixels:\n",
    "    rng = np.random.default_rng()\n",
    "  for epoch in range(epoch):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "      inputs, labels = data[0].to(device), data[1].to(device)\n",
    "      if random_shuffle:\n",
    "        # The permutation should be the same for every epoch\n",
    "        torch.manual_seed(0)\n",
    "        labels = labels[torch.randperm(len(labels))]\n",
    "      if shuffled_pixels:\n",
    "        data_ = inputs.cpu().numpy()\n",
    "        # Resetting the random generator every time to generate the same set of permutation\n",
    "        rng = np.random.default_rng(26)\n",
    "        data_perm = rng.permutation(data_, axis=2)\n",
    "        data = torch.from_numpy(data_perm)\n",
    "      if random_pixels:\n",
    "        data_ = inputs.cpu().numpy()\n",
    "        # Generating a different set of permutation every time\n",
    "        data_perm = rng.permutation(data_, axis=2)\n",
    "        data = torch.from_numpy(data_perm)\n",
    "      if gaussian_noise:\n",
    "        batch = inputs.shape[0]\n",
    "        w = inputs.shape[-1]\n",
    "        h = inputs.shape[-2]\n",
    "        data = get_gaussian_image(batch, w, h)\n",
    "  # End\n",
    "      \"\"\"\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      step_count += 1\n",
    "      if step_count%1000==0:\n",
    "        acc_t,acc_v = eval_model(model,trainloader,testloader)\n",
    "        model.train()\n",
    "        history_t.append(acc_t)\n",
    "        history_v.append(acc_v)\n",
    "        log_ = str(step_count)+\",\"+str(acc_t)+\",\"+str(acc_v)+ \",\" + str(running_loss/1000)+\"\\n\"\n",
    "        with open(\"{}.log\".format(name), \"a\") as f:\n",
    "          f.write(log_)\n",
    "    print(\"Epoch {} | loss: {:.4f} | Train acc: {:.4f} | Val acc: {:.4f}\".format(epoch+1, running_loss/1000,acc_t, acc_v))\n",
    "    history_loss.append(running_loss/1000)\n",
    "    scheduler.step()\n",
    "    \"\"\"\n",
    "        model.train()\n",
    "        train_loss, train_acc = run_train_single_epoch(trainloader, model, device, criterion, optimizer)\n",
    "        model.eval()\n",
    "        valid_loss, valid_acc = run_validation_single_epoch(testloader, model, device, criterion)\n",
    "        print(\"[Epoch {}] Train Loss: {} Vaidation Loss: {} Train Acc: {} Validation Acc: {}\".format(\\\n",
    "              epoch, train_loss, valid_loss, train_acc, valid_acc))\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        valid_accs.append(valid_acc)\n",
    "        if valid_acc > highest_acc:\n",
    "            torch.save(model.state_dict(), \"{}.pth\".format(name))\n",
    "            highest_acc = valid_acc\n",
    "        # else:\n",
    "        #     print(\"Early stopping.\")\n",
    "        #     break\n",
    "    print('Finished Training')\n",
    "  return model,history_t,history_v, history_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.95)\n",
    "train_losses, valid_losses, train_accs, validation_accs\n",
    "trained_model,history_t1,history_v1, history_loss = fit(100, model, trainloader, testloader, optimizer,scheduler, name='normal_labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
